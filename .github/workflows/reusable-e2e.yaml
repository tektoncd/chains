
name: Reusable workflow example

on:
  workflow_call:
    inputs:
      pipelines-release:
        required: true
        type: string
      k8s-version:
        required: true
        type: string

defaults:
  run:
    shell: bash
    working-directory: ./

jobs:
  e2e-test:
    name: e2e test
    runs-on: ubuntu-22.04

    env:
      GOPATH: ${{ github.workspace }}
      GO111MODULE: on
      GOFLAGS: -ldflags=-s -ldflags=-w
      KO_DOCKER_REPO: registry.local:5000/knative
      KOCACHE: ~/ko
      SIGSTORE_SCAFFOLDING_RELEASE_VERSION: "v0.7.24"
      TEKTON_PIPELINES_RELEASE: "https://storage.googleapis.com/tekton-releases/pipeline/previous/${{ inputs.pipelines-release }}/release.yaml"
      # Note that we do not include the v prefix here so we can use it in all
      # the places this is used.
      SKIP_INITIALIZE: true

    steps:
    - name: Set up Go
      uses: actions/setup-go@0a12ed9d6a96ab950c8f026ed9f722fe0da7ef32 # v5.0.2
      with:
        go-version: 1.22.x

    - uses: ko-build/setup-ko@d006021bd0c28d1ce33a07e7943d48b079944c8d # v0.9
      with:
        version: tip

    - name: Check out our repo
      uses: actions/checkout@6d193bf28034eafb982f37bd894289fe649468fc # v4.1.7
      with:
        path: ./src/github.com/tektoncd/chains

    - name: Install mirror, kind, knative + sigstore
      uses: sigstore/scaffolding/actions/setup@d40cf576f588d980142f0b8462c425d7b32f00b1 # v0.7.25
      with:
        k8s-version: ${{ inputs.k8s-version }}
        version: ${{ env.SIGSTORE_SCAFFOLDING_RELEASE_VERSION }}
        knative-version: 1.9.0

    - name: Install Tekton pipelines
      run: |
        while ! kubectl apply --filename ${{ env.TEKTON_PIPELINES_RELEASE }}
        do
          echo "waiting for tekton pipelines to get installed"
          sleep 2
        done

        # Restart so picks up the changes.
        kubectl -n tekton-pipelines delete po -l app=tekton-pipelines-controller

    - name: Run integration tests
      working-directory: ./src/github.com/tektoncd/chains
      run: |
        ./test/presubmit-tests.sh --integration-tests


    - name: Run tutorial taskrun
      run: |
        kubectl patch configmap/chains-config \
        --namespace tekton-chains \
        --type merge \
        --patch '{"data":{"artifacts.oci.format": "simplesigning", "artifacts.oci.storage": "oci", "artifacts.taskrun.format": "in-toto", "signers.x509.fulcio.address": "http://fulcio.fulcio-system.svc", "signers.x509.fulcio.enabled": "true", "transparency.enabled": "true", "transparency.url": "http://rekor.rekor-system.svc"}}'

        # Restart chains controller so picks up the changes.
        kubectl -n tekton-chains delete po -l app=tekton-chains-controller

        # TODO(vaikas): Better way to find when the chains has picked up
        # the changes
        sleep 20

        kubectl create -f https://raw.githubusercontent.com/tektoncd/chains/main/examples/taskruns/task-output-image.yaml

        # Sleep so the taskrun shows up.
        sleep 2

        echo "Waiting for the taskrun to complete..."
        kubectl wait --timeout 3m --for=condition=Succeeded taskruns --all || kubectl get taskruns -o yaml

        echo "Waiting for Chains to do it's thing"
        for i in {1..10}
        do
          tkn tr describe --last -o jsonpath="{.metadata.annotations.chains\.tekton\.dev/transparency}" > tektonentry

          if [ -s ./tektonentry ]; then
            if grep --quiet rekor.rekor-system.svc ./tektonentry ; then
              echo "Found rekor transparency entry:"
              cat ./tektonentry
              kubectl get taskruns -oyaml
              exit 0
            else
              echo "Did not find expected rekor transparency entry"
              sleep 2
            fi
          else
            echo "Did not find rekor transparency entry in the annotations"
            sleep 2
          fi
        done

        # Did not find entry, fail
        exit 1

    - name: Collect diagnostics
      if: ${{ failure() }}
      uses: chainguard-dev/actions/kind-diag@5363dd9eb48083bbf7674a4bbe62d71c3b230edd # v1.1.2
      with:
        cluster-resources: nodes
        namespace-resources: pods,taskruns,jobs
